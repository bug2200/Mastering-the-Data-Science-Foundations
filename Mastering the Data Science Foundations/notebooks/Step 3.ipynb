{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# Step 3: Build Model\n",
    "## 1.1 Model Selection\n",
    "The target variable in this project is the `score`, which represents a continuous engagement score for each student. Because the outcome is numeric and not a discrete class label, this is primarily a **regression problem**, not a classification problem.\n",
    "\n",
    "The goal is to predict the engagement score based on early behavioural and demographic features. Using regression allows the model to capture gradual differences in engagement levels instead of forcing students into a small number of discrete categories.\n",
    "\n",
    "To explore different modelling approaches and compare performance, three supervised regression models will be tested:\n",
    "\n",
    "1. **Linear Regression** – a simple, interpretable baseline model that assumes a linear relationship between features and engagement score.\n",
    "2. **k-Nearest Neighbors Regressor (KNN)** – a non-parametric model that predicts scores based on similar students in the feature space, capturing local patterns.\n",
    "3. **Random Forest Regressor** – an ensemble of decision trees that can model non-linear relationships and interactions between features, often providing strong performance on tabular data.\n",
    "\n",
    "These models cover a range from simple and interpretable (linear regression) to more flexible and powerful (Random Forest), allowing for a meaningful comparison of bias–variance trade-offs.\n"
   ],
   "id": "10b0e64819411c01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T11:43:32.300151Z",
     "start_time": "2025-11-22T11:43:32.248642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load the cleaned, preprocessed dataset\n",
    "df = pd.read_csv(\"../data/cleaned_student_data.csv\")\n",
    "\n",
    "# 2. Define target (y)\n",
    "target_col = \"score\"\n",
    "y = df[target_col]\n",
    "\n",
    "# 3. Define features (X): drop target and keep only numeric columns for modelling\n",
    "X = df.drop(columns=[target_col])\n",
    "X = X.select_dtypes(include=[\"int64\", \"float64\"])\n",
    "\n",
    "print(\"Final numeric feature columns used for modelling:\")\n",
    "print(X.columns.tolist())\n",
    "\n",
    "print(\"\\nShape of feature matrix X:\", X.shape)\n",
    "print(\"Shape of target vector y:\", y.shape)\n",
    "\n",
    "# 4. Train–test split to avoid data leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTraining set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n"
   ],
   "id": "3f4c29023b9094d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final numeric feature columns used for modelling:\n",
      "['age', 'logged in', 'lessons', 'assignments', 'posts', 'orientation', 'total_activity', 'has_activity', 'lessons_assignments_ratio']\n",
      "\n",
      "Shape of feature matrix X: (500, 9)\n",
      "Shape of target vector y: (500,)\n",
      "\n",
      "Training set size: 400\n",
      "Test set size: 100\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Interpretation\n",
    "\n",
    "The cleaned dataset was loaded and split into features (`X`) and target (`y`), where `score` is the engagement outcome to be predicted. A train–test split was applied with 80% of the data used for training and 20% held out for testing. This separation helps prevent data leakage and provides an unbiased estimate of model performance. The resulting shapes of `X_train`, `X_test`, `y_train`, and `y_test` confirm that the data is ready for model training in the next step.\n"
   ],
   "id": "4a6068120e856a09"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.1 Train baseline model\n",
    "\n",
    "A baseline model provides a simple point of comparison to understand whether more complex models offer meaningful improvements. In regression problems, baseline models help establish the minimum acceptable performance before exploring advanced approaches.\n",
    "\n",
    "In this step, three baseline regressors will be trained:\n",
    "- **Linear Regression** – a simple, interpretable model that assumes a linear relationship between features and engagement score.\n",
    "- **k-Nearest Neighbors Regressor (KNN)** – a non-parametric model that predicts engagement based on the average score of similar students in the feature space.\n",
    "- **Random Forest Regressor** – an ensemble of decision trees that can capture non-linear patterns and interactions between variables.\n",
    "\n",
    "Training these models creates a strong foundation for comparison during evaluation and later hyperparameter tuning.\n"
   ],
   "id": "11ee1d3ade7f4c9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T11:43:50.034035Z",
     "start_time": "2025-11-22T11:43:49.870138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the baseline models\n",
    "lin_reg = LinearRegression()\n",
    "knn_reg = KNeighborsRegressor()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train all models on the training set\n",
    "lin_reg.fit(X_train, y_train)\n",
    "knn_reg.fit(X_train, y_train)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Baseline models trained successfully.\")\n"
   ],
   "id": "f6d9b6ba874f32f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline models trained successfully.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Interpretation\n",
    "\n",
    "All three baseline models were successfully trained on the training data. These baselines will serve as reference points for performance assessment and hyperparameter tuning in the next steps.\n"
   ],
   "id": "a52edd328d0f7ff8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T11:37:49.578763Z",
     "start_time": "2025-11-22T11:37:49.539185Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## 3.1 Evaluate model performance\n",
    "\n",
    "To compare the baseline models, each one must be evaluated on the test dataset using regression-appropriate metrics. The following metrics will be used:\n",
    "\n",
    "- **Mean Squared Error (MSE)**: Measures the average squared difference between predicted and true values. Lower values indicate better performance but MSE is sensitive to outliers.\n",
    "- **Root Mean Squared Error (RMSE)**: The square root of MSE, expressed in the same units as the target variable. Easier to interpret than MSE.\n",
    "- **R-squared (R²)**: Represents the proportion of variance in the target explained by the model. Higher values indicate better fit, with 1.0 being a perfect fit.\n",
    "\n",
    "These metrics provide complementary insights:\n",
    "MSE/RMSE evaluate the magnitude of prediction errors, while R² assesses how well each model explains the engagement score.\n",
    "\n"
   ],
   "id": "683682d6aee0783f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T11:46:03.483873Z",
     "start_time": "2025-11-22T11:46:03.423961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate predictions\n",
    "y_pred_lin = lin_reg.predict(X_test)\n",
    "y_pred_knn = knn_reg.predict(X_test)\n",
    "y_pred_rf = rf_reg.predict(X_test)\n",
    "\n",
    "# Compute metrics\n",
    "results = {\n",
    "    \"Model\": [\"Linear Regression\", \"KNN Regressor\", \"Random Forest Regressor\"],\n",
    "    \"MSE\": [\n",
    "        mean_squared_error(y_test, y_pred_lin),\n",
    "        mean_squared_error(y_test, y_pred_knn),\n",
    "        mean_squared_error(y_test, y_pred_rf)\n",
    "    ],\n",
    "    \"RMSE\": [\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_lin)),\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_knn)),\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "    ],\n",
    "    \"R² Score\": [\n",
    "        r2_score(y_test, y_pred_lin),\n",
    "        r2_score(y_test, y_pred_knn),\n",
    "        r2_score(y_test, y_pred_rf)\n",
    "    ]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n"
   ],
   "id": "1c060004d82b0f54",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     Model       MSE      RMSE  R² Score\n",
       "0        Linear Regression  0.423249  0.650576  0.635721\n",
       "1            KNN Regressor  0.467857  0.684001  0.597327\n",
       "2  Random Forest Regressor  0.428382  0.654509  0.631303"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R² Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.423249</td>\n",
       "      <td>0.650576</td>\n",
       "      <td>0.635721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.467857</td>\n",
       "      <td>0.684001</td>\n",
       "      <td>0.597327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.428382</td>\n",
       "      <td>0.654509</td>\n",
       "      <td>0.631303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Interpretation\n",
    "\n",
    "The performance table shows how each baseline model performs across multiple regression metrics.\n",
    "- **Lower MSE and RMSE** indicate more accurate predictions.\n",
    "- **Higher R² values** indicate that the model explains more variance in engagement score.\n",
    "\n",
    "These baseline results provide a reference point for assessing whether tuned or more advanced models offer meaningful performance improvements.\n"
   ],
   "id": "da4d5f3bc634a7e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Interpret results\n",
    "\n",
    "The baseline evaluation highlights several important differences across the three models:\n",
    "\n",
    "### **4.1 Linear Regression performs the best overall**\n",
    "Linear Regression achieves the:\n",
    "- **lowest MSE (0.423)**\n",
    "- **lowest RMSE (0.651)**\n",
    "- **highest R² (0.636)**\n",
    "\n",
    "This indicates that a simple linear relationship explains a substantial portion of the variance in engagement score. The relatively strong performance of this model suggests that early behavioural features (logged-in hours, lessons, assignments) have a mostly linear association with engagement.\n",
    "\n",
    "### **4.2 Random Forest performs similarly but does not outperform Linear Regression**\n",
    "Random Forest achieves:\n",
    "- MSE and RMSE nearly identical to Linear Regression\n",
    "- Slightly lower R² (0.631)\n",
    "\n",
    "While Random Forest is capable of capturing non-linear patterns, this small difference suggests that:\n",
    "- either the dataset is not large enough for the ensemble model to shine\n",
    "- or the underlying relationships are not strongly non-linear\n",
    "- or the default hyperparameters may not be optimal\n",
    "\n",
    "This model may still improve with tuning in a later step.\n",
    "\n",
    "### **4.3 KNN performs the worst**\n",
    "KNN has:\n",
    "- the **highest MSE (0.468)**\n",
    "- the **highest RMSE (0.684)**\n",
    "- the **lowest R² (0.597)**\n",
    "\n",
    "This suggests that engagement scores are **not well predicted by local neighbourhood structure** in the feature space. High-dimensional numeric data (even after scaling) tends to reduce the effectiveness of KNN because distances become less meaningful.\n",
    "\n",
    "### **Key Insight**\n",
    "Overall, Linear Regression provides the strongest baseline and indicates that the relationship between early activity and engagement is relatively stable and predictable. Random Forest shows potential and may improve with hyperparameter tuning, while KNN appears less suitable for this specific prediction task.\n",
    "\n",
    "These findings will guide the next step: evaluating whether tuning more flexible models (such as Random Forest) can meaningfully outperform the linear baseline.\n"
   ],
   "id": "cbccb11d5dc3fed9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
