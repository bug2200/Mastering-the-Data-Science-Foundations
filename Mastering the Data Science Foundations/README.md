# Mastering the Data Science Foundations â€“ Student Alex Bataniuc

This repository contains the full project for the **Mastering the Data Science Foundations** module.  
The goal of the project is to explore, clean, model, and interpret student engagement data from Tomorrow University to predict which students will become highly engaged by mid-semester.
## ğŸ“‚ Project Structure

```
Mastering the Data Science Foundations/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ student_data.db
â”‚   â”œâ”€â”€ cleaned_student_data.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ Step_1.ipynb
â”‚   â”œâ”€â”€ Step_2.ipynb
â”‚   â”œâ”€â”€ Step_3.ipynb
â”‚   â”œâ”€â”€ Step_4.ipynb
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## ğŸš€ How to Run the Project
### 1. Access

GitHub: https://github.com/bug2200/Mastering-the-Data-Science-Foundations.git

### 2. Open the notebooks

All project notebooks are inside the `notebooks/` folder:

- `Step_1.ipynb` â€“ Exploratory Data Analysis  
- `Step_2.ipynb` â€“ Cleaning & Feature Engineering  
- `Step_3.ipynb` â€“ Baseline Modeling  
- `Step_4.ipynb` â€“ Model Tuning & Interpretation

### 3. Dataset paths are already configured

All notebooks automatically load data from:  
../data/student_data.db  
../data/cleaned_student_data.csv

### 4. Requirements

The project uses standard Python data science libraries.  
All dependencies are listed in the `requirements.txt` file.

Here is the full list used in this project:  
pandas  
numpy  
matplotlib  
seaborn  
scikit-learn   
jupyter

To install everything at once:  
`pip install -r requirements.txt`
---
## ğŸ“˜ Dataset Description
The project uses anonymized student engagement data provided by Tomorrow University.  
The dataset includes the first 4 weeks of behavioral activity after enrollment.

### Files
- **`student_data.db`** â€“ original SQLite database containing all raw student records.
- **`cleaned_student_data.csv`** â€“ the fully preprocessed dataset generated in Step 2 (ready for modeling).

### Features
The dataset contains the following variables:

- **sex** â€“ gender identity (categorical)
- **birthdate** â€“ date of birth (string format)
- **age** â€“ student age (numeric)
- **country** â€“ country of residence
- **logged in** â€“ hours logged into the learning app during the first 4 weeks
- **lessons** â€“ number of completed lessons
- **assignments** â€“ number of submitted assignments
- **posts** â€“ number of discussion posts
- **mentoring** â€“ whether the student signed up for the mentoring program (Yes/No)
- **orientation** â€“ participation in the in-person orientation event (0/1)
- **score** â€“ engagement score (target variable)
---
## ğŸ“Š Analysis Summary

The project follows a complete data science workflow, split across four structured notebooks:

### **Step 1 â€“ Exploratory Data Analysis (EDA)**
- Examined distributions, missing values, and potential outliers  
- Explored relationships between behavioural features and engagement score  
- Identified initial patterns supporting the project hypothesis  

### **Step 2 â€“ Data Cleaning & Feature Engineering**
- Imputed missing values using context-aware methods  
- Handled inconsistent entries and removed structurally invalid values  
- Created new features (total activity)  
- Standardized numerical features and encoded categorical variables  

### **Step 3 â€“ Baseline Modeling**
- Selected regression as the appropriate model type  
- Trained Linear Regression, KNN, and Random Forest  
- Evaluated performance using MSE, RMSE, and RÂ²  
- Identified Linear Regression as the strongest baseline performer  

### **Step 4 â€“ Model Tuning & Interpretation**
- Tuned Random Forest using GridSearchCV  
- Compared tuned vs baseline models  
- Created interpretability visualisations (RMSE vs RÂ² bubble chart, feature importance)  
- Confirmed that Linear Regression remains the best-performing model  

## Final Model Selection

After evaluating all baseline models and testing a tuned version of Random Forest, the final selected model for predicting student engagement is:
 **ğŸ† Linear Regression**

### âœ” Why Linear Regression was selected
- It achieved the **lowest RMSE** and **highest RÂ²** among all tested models.
- It generalised better than both Random Forest and KNN.
- Random Forest tuning did **not** improve performance and slightly worsened test-set accuracy.
- The underlying relationships in the dataset appear mostly **linear**, making Linear Regression the most appropriate and interpretable choice.
- The model provides strong predictive performance while remaining simple, transparent, and easy to communicate to stakeholders.

### âœ” What this means for the data
Early behavioural activity, especially lessons, assignments, and logged-in hours - shows a clear linear relationship with engagement.  
This suggests that simple, interpretable models can successfully identify early predictors of engagement without requiring more complex non-linear algorithms.

